{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a4ada12",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9a3efc67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Library\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78435d65",
   "metadata": {},
   "source": [
    "# Importing Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5107d232",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting Variables\n",
    "path = r'C:\\Users\\Saikat Halder\\Documents\\CareerFoundry\\Data Immersion\\Achievement 4\\Instacart Basket Analysis 01182024'\n",
    "path_mac = r'/Users/saikathalder/CareerFoundry/Data Immersion/Achievement 4/Instacart Basket Analysis 01182024'\n",
    "#Importing products from Original Data\n",
    "df_prods=pd.read_csv(os.path.join(path_mac, '02 Data', 'Original Data', 'products.csv'), index_col = False)\n",
    "#Importing orders from Prepared Data\n",
    "df_ords=pd.read_csv(os.path.join(path_mac, '02 Data', 'Prepared Data', 'orders_wrangled_2.csv'), index_col = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2feedf4b",
   "metadata": {},
   "source": [
    "# 1.0 Consistency Checks on df_prods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "188eccc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49693"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of rows\n",
    "df_prods.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d183e4",
   "metadata": {},
   "source": [
    "## Mixed Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "38f18072",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_name\n"
     ]
    }
   ],
   "source": [
    "found_mix_type = False\n",
    "\n",
    "for col in df_prods.columns.tolist():\n",
    "  weird = (df_prods[[col]].map(type) != df_prods[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_prods[weird]) > 0:\n",
    "    print (col)\n",
    "    found_mix_type = True\n",
    "    \n",
    "if not found_mix_type:\n",
    "    print('There are no mix type columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cb115cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object\n"
     ]
    }
   ],
   "source": [
    "# Checking for data types for product_name\n",
    "product_name_data_type = df_prods['product_name'].dtype\n",
    "print(product_name_data_type)\n",
    "# product_name only has stings as data type. This confirms that there is no mixed data type in product_name. \n",
    "#The reason because found_mix_type is coming True might be because of the NUll values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad44e01c",
   "metadata": {},
   "source": [
    "## Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "60732178",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "product_id        0\n",
      "product_name     16\n",
      "aisle_id          0\n",
      "department_id     0\n",
      "prices            0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values\n",
    "print(df_prods.isnull().sum())\n",
    "# it seems product_name has 16 missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2cd71335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id product_name  aisle_id  department_id  prices\n",
      "33             34          NaN       121             14    12.2\n",
      "68             69          NaN        26              7    11.8\n",
      "115           116          NaN        93              3    10.8\n",
      "261           262          NaN       110             13    12.1\n",
      "525           525          NaN       109             11     1.2\n",
      "1511         1511          NaN        84             16    14.3\n",
      "1780         1780          NaN       126             11    12.3\n",
      "2240         2240          NaN        52              1    14.2\n",
      "2586         2586          NaN       104             13    12.4\n",
      "3159         3159          NaN       126             11    13.1\n",
      "3230         3230          NaN       120             16    14.4\n",
      "3736         3736          NaN        41              8    14.8\n",
      "4283         4283          NaN        77              7    14.4\n",
      "4790         4790          NaN        91             16    14.5\n",
      "38187       38183          NaN        39             12    20.9\n",
      "40444       40440          NaN       120             16    14.8\n"
     ]
    }
   ],
   "source": [
    "# Creating a subset for null values from the product_name\n",
    "df_nan = df_prods[df_prods['product_name'].isnull()==True]\n",
    "print (df_nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f18171c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49693\n"
     ]
    }
   ],
   "source": [
    "# Counting rows in product_name\n",
    "print(df_prods['product_name'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cc531a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49677\n"
     ]
    }
   ],
   "source": [
    "# Creating a new dataframe by removing the rows with null values\n",
    "df_prods_clean =  df_prods[df_prods['product_name'].isnull()==False]\n",
    "# Verifying row counts in df_prods_clean\n",
    "print(df_prods_clean['product_name'].shape[0])\n",
    "# 16 rows have been removed\n",
    "# The following can be used to replace df_prods by removing the missing values\n",
    "    #df.prods.dropna(inplace = True)\n",
    "    #df_prods.dropna(subset= ['product_name'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc072ee2",
   "metadata": {},
   "source": [
    "## Duplicate Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d92c90b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       product_id                                       product_name  \\\n",
      "462           462                  Fiber 4g Gummy Dietary Supplement   \n",
      "18459       18458                                         Ranger IPA   \n",
      "26810       26808               Black House Coffee Roasty Stout Beer   \n",
      "35309       35306  Gluten Free Organic Peanut Butter & Chocolate ...   \n",
      "35495       35491                            Adore Forever Body Wash   \n",
      "\n",
      "       aisle_id  department_id  prices  \n",
      "462          70             11     4.8  \n",
      "18459        27              5     9.2  \n",
      "26810        27              5    13.4  \n",
      "35309       121             14     6.8  \n",
      "35495       127             11     9.9  \n"
     ]
    }
   ],
   "source": [
    "# Finding Duplicates\n",
    "df_dups = df_prods_clean[df_prods_clean.duplicated()]\n",
    "print(df_dups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92ee0453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "# Finding number of rows which have duplicates\n",
    "print(df_dups.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c9233d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49677\n"
     ]
    }
   ],
   "source": [
    "# Finding number of rows in df_prods_clean\n",
    "print(df_prods_clean.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c0c241d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49672\n"
     ]
    }
   ],
   "source": [
    "# Removing Duplicates\n",
    "df_prods_clean_no_dups = df_prods_clean.drop_duplicates()\n",
    "# Verifying number of rows in df_prods_clean_no_dups\n",
    "print(df_prods_clean_no_dups.shape[0])\n",
    "# 5 rows have been removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b997e2a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no mix type columns\n"
     ]
    }
   ],
   "source": [
    "# Checking for mixed type data after Null values and duplicates are removed\n",
    "found_mix_type = False\n",
    "\n",
    "for col in df_prods_clean_no_dups.columns.tolist():\n",
    "  weird = (df_prods_clean_no_dups[[col]].map(type) != df_prods_clean_no_dups[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_prods_clean_no_dups[weird]) > 0:\n",
    "    print (col)\n",
    "    found_mix_type = True\n",
    "    \n",
    "if not found_mix_type:\n",
    "    print('There are no mix type columns')\n",
    "# This confirms that there are no coulumns with mixed data in df_prods_clean_no_dups"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4edc65aa",
   "metadata": {},
   "source": [
    "# 2.0 Interpreting df.describe() on df_ords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f67fdb97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                   object\n",
      "user_id                    object\n",
      "order_number               object\n",
      "order_day_of_week           int64\n",
      "order_hour_of_day           int64\n",
      "days_since_prior_order    float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Changing the datatype for order_id, user_id, order_number to string\n",
    "df_ords['order_id'] = df_ords['order_id'].astype('str')\n",
    "df_ords['user_id'] = df_ords['user_id'].astype('str')\n",
    "df_ords['order_number'] = df_ords['order_number'].astype('str')\n",
    "# Verifying the data type change\n",
    "print(df_ords.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9e000a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       order_day_of_week  order_hour_of_day  days_since_prior_order\n",
      "count       3.421083e+06       3.421083e+06            3.214874e+06\n",
      "mean        2.776219e+00       1.345202e+01            1.111484e+01\n",
      "std         2.046829e+00       4.226088e+00            9.206737e+00\n",
      "min         0.000000e+00       0.000000e+00            0.000000e+00\n",
      "25%         1.000000e+00       1.000000e+01            4.000000e+00\n",
      "50%         3.000000e+00       1.300000e+01            7.000000e+00\n",
      "75%         5.000000e+00       1.600000e+01            1.500000e+01\n",
      "max         6.000000e+00       2.300000e+01            3.000000e+01\n"
     ]
    }
   ],
   "source": [
    "print(df_ords.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565a4557",
   "metadata": {},
   "source": [
    "## order_day_of_week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bf2b13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Minimum of 0, the Maximum of 6 and the Median of 3 seems consistent with the data that is supposed to be present\n"
     ]
    }
   ],
   "source": [
    "print('The Minimum of 0, the Maximum of 6 and the Median of 3 seems consistent with the data that is supposed to be present')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2bf2403",
   "metadata": {},
   "source": [
    "## order_hour_of_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fc46ea49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Minimum of 0, the Maximum of 23 and the Median of 13 is consistent with the data that is supposed to be present\n"
     ]
    }
   ],
   "source": [
    "print('The Minimum of 0, the Maximum of 23 and the Median of 13 is consistent with the data that is supposed to be present')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71abff98",
   "metadata": {},
   "source": [
    "## days_since_prior_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5dd7c3a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Minimum of 0, the Maximum of 30 and the Median of 7 seems consistent with the data that is supposed to be present\n"
     ]
    }
   ],
   "source": [
    "print('The Minimum of 0, the Maximum of 30 and the Median of 7 seems consistent with the data that is supposed to be present')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d6fec0",
   "metadata": {},
   "source": [
    "# 3.0 Checking for mixed type of data in the df_ords dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5b82a32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no mix type columns\n"
     ]
    }
   ],
   "source": [
    "# Check for mixed types\n",
    "found_mix_type = False\n",
    "\n",
    "for col in df_ords.columns.tolist():\n",
    "  weird = (df_ords[[col]].map(type) != df_ords[[col]].iloc[0].apply(type)).any(axis = 1)\n",
    "  if len (df_ords[weird]) > 0:\n",
    "    print (col)\n",
    "    found_mix_type = True\n",
    "    \n",
    "if not found_mix_type:\n",
    "    print('There are no mix type columns')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645a184b",
   "metadata": {},
   "source": [
    "# 4.0 Address the mixed_type data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "bee11301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no mixed type data in df_ords dataframe\n"
     ]
    }
   ],
   "source": [
    "print('There are no mixed type data in df_ords dataframe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5af9a43e",
   "metadata": {},
   "source": [
    "# 5.0 Run a check for missing values in your df_ords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1023d99c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                       0\n",
      "user_id                        0\n",
      "order_number                   0\n",
      "order_day_of_week              0\n",
      "order_hour_of_day              0\n",
      "days_since_prior_order    206209\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Finding missing values\n",
    "print(df_ords.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "90f1a2af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2168274</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1374495</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>3343014</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2717275</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>2086598</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>2565571</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>600894</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>280530</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>1224907</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id user_id order_number  order_day_of_week  order_hour_of_day  \\\n",
       "0   2539329       1            1                  2                  8   \n",
       "11  2168274       2            1                  2                 11   \n",
       "26  1374495       3            1                  1                 14   \n",
       "39  3343014       4            1                  6                 11   \n",
       "45  2717275       5            1                  3                 12   \n",
       "50  2086598       6            1                  5                 18   \n",
       "54  2565571       7            1                  3                  9   \n",
       "75   600894       8            1                  6                  0   \n",
       "79   280530       9            1                  1                 17   \n",
       "83  1224907      10            1                  2                 14   \n",
       "\n",
       "    days_since_prior_order  \n",
       "0                      NaN  \n",
       "11                     NaN  \n",
       "26                     NaN  \n",
       "39                     NaN  \n",
       "45                     NaN  \n",
       "50                     NaN  \n",
       "54                     NaN  \n",
       "75                     NaN  \n",
       "79                     NaN  \n",
       "83                     NaN  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a subset for null values in the days_since_prior_order\n",
    "df_nan_ords = df_ords[df_ords['days_since_prior_order'].isnull()==True]\n",
    "#Showing the first 10 rows where days_since_prior_order is null\n",
    "df_nan_ords.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "2e9f524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "order_id                  0\n",
      "user_id                   0\n",
      "order_number              0\n",
      "order_day_of_week         0\n",
      "order_hour_of_day         0\n",
      "days_since_prior_order    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Filter the DataFrame based where order_number is not '1'\n",
    "filtered_df = df_nan_ords[df_nan_ords['order_number'] != '1']\n",
    "#Count the number of order where the order_number is not '1'\n",
    "print(filtered_df.count())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0f68ddb",
   "metadata": {},
   "source": [
    "## Explanation of the missing values in days_since_prior_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8c1d9c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When I saw that the order_number is 1 for the first 10 rows of order where the days_since_prior_order is null. I filtered the dataframe into a sub-dataframe where the order_number is not 1. This resulted a dataframe with no values. This means since this is the first order for each customer, the dataframe does not have any valeus for days_since_prior_order.\n"
     ]
    }
   ],
   "source": [
    "print('When I saw that the order_number is 1 for the first 10 rows of order where the days_since_prior_order is null. I filtered the dataframe into a sub-dataframe where the order_number is not 1. This resulted a dataframe with no values. This means since this is the first order for each customer, the dataframe does not have any valeus for days_since_prior_order.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992bdb37",
   "metadata": {},
   "source": [
    "# 6.0 Address the missing values using an appropriate method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "775458e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of df_ords\n",
    "original_df_ords = df_ords.copy()\n",
    "df_ords_clean = original_df_ords.copy()\n",
    "\n",
    "#Replacing the NaN values with '0' in a df_ords_clean\n",
    "df_ords_clean['days_since_prior_order'] = df_ords_clean['days_since_prior_order'].fillna('0')\n",
    "\n",
    "# Checking for missing values\n",
    "#print(df_ords_clean.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8f3f4e13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_day_of_week</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2539329</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2398795</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  order_id user_id order_number  order_day_of_week  order_hour_of_day  \\\n",
       "0  2539329       1            1                  2                  8   \n",
       "1  2398795       1            2                  3                  7   \n",
       "2   473747       1            3                  3                 12   \n",
       "3  2254736       1            4                  4                  7   \n",
       "4   431534       1            5                  4                 15   \n",
       "\n",
       "  days_since_prior_order  \n",
       "0                      0  \n",
       "1                   15.0  \n",
       "2                   21.0  \n",
       "3                   29.0  \n",
       "4                   28.0  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ords_clean.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b509c3a",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b8172e03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Since the NaN values are due to the order being the first order for each customer, I replaced the NaN values with 0\n"
     ]
    }
   ],
   "source": [
    "print('Since the NaN values are due to the order being the first order for each customer, I replaced the NaN values with 0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0635c8d",
   "metadata": {},
   "source": [
    "# 7.0 Run a check for duplicate values in your df_ords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7d7612bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate values\n"
     ]
    }
   ],
   "source": [
    "# Creating a subset with duplicate values\n",
    "df_dups_ords = df_ords_clean[df_ords_clean.duplicated()]\n",
    "# Checking if there are any records in df_dups_ords\n",
    "\n",
    "if df_dups_ords.shape[0] == 0:\n",
    "    print('There are no duplicate values')\n",
    "else:\n",
    "    print('Yes! there are duplicate values')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "440a7ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3421083"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking number of rows\n",
    "df_ords_clean.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf0474e",
   "metadata": {},
   "source": [
    "# 8.0 Address the duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0819abdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no duplicate values in df_ords_clean\n"
     ]
    }
   ],
   "source": [
    "print('There are no duplicate values in df_ords_clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d581cb0",
   "metadata": {},
   "source": [
    "# 9.0 Export the cleaned df_prods and df_ords into .csv files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fe311fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting df_ords_clean\n",
    "df_ords_clean.to_csv(os.path.join(path_mac, '02 Data', 'Prepared Data', 'orders_consistency_checked.csv'), index = False)\n",
    "# Exporting df_prods_clean_no_dups\n",
    "df_prods_clean_no_dups.to_csv(os.path.join(path_mac, '02 Data', 'Prepared Data', 'products_consistency_checked.csv'), index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1d9a65",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
